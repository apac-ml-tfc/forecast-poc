{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating and Importing Related Time Series Data\n",
    "\n",
    "## Obtaining Your Data\n",
    "\n",
    "This will take off where you stopped regarding your target time series data. In this particular exmaple, one master file contained both the target and the related time series information. That may or may not be the case for your problem. The goal here is to produce a file that contains the following 2 required attributes:\n",
    "\n",
    "1. Timestamp - Must be of the same format and total range as the target-time series data, as well as slices of values into the dates for your forecast.\n",
    "1. Item_ID - Must exist for all the time stamps for each item in your time series dataset\n",
    "\n",
    "In addition to those attributes we are looking for variables that shift over time that are impactful in some way towards our desired goal of predicting traffic volumes.\n",
    "\n",
    "Again the data was already bundled together for us in this sample so we will skip obtaining it a second time but that is where you would start otherwise.\n",
    "\n",
    "With the data ready to go, skip the blank cell ( feel free to add to it if you need to manipulate your own data) and execute the cells to handle our imports and retrieving our stored values from the previous notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "from time import sleep\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Related Time Series File\n",
    "\n",
    "The challenge here is to make sure that we leave absolutely 0 entries with NaN values or the service will throw an error when building a Predictor. This is because the values must be present in order for us to make assumptions about their impact overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-01 00:00:00\n",
      "2018-09-30 23:00:00\n"
     ]
    }
   ],
   "source": [
    "related_time_series_df = target_df.copy()\n",
    "related_time_series_df.dropna()\n",
    "related_time_series_df = full_df.join(related_time_series_df, how='outer')\n",
    "cols = related_time_series_df.columns.tolist()\n",
    "related_time_series_df[cols] = related_time_series_df[cols].replace('', np.nan).ffill()\n",
    "related_time_series_df = related_time_series_df.loc['2017-01-01':]\n",
    "print (related_time_series_df.index.min())\n",
    "print (related_time_series_df.index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that the data covers the range of our target time series of 2017's entire year to the end of our known data about 2018. We have not yet defined a forecast horizon yet but it is important to note here that the related data needs to cover that time span. To spoil later work, the horizon for us is 480 hours or 20 days, plenty of time with 9 months of validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly on prepping the base set of the data we validate there are no blanks or NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [holiday, temp, rain_1h, snow_1h, clouds_all, weather_main, weather_description, traffic_volume]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_time_series_df[related_time_series_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the columns and decide what we should keep:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-12 07:00:00</th>\n",
       "      <td>None</td>\n",
       "      <td>290.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Mist</td>\n",
       "      <td>mist</td>\n",
       "      <td>6068.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 17:00:00</th>\n",
       "      <td>None</td>\n",
       "      <td>274.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Drizzle</td>\n",
       "      <td>light intensity drizzle</td>\n",
       "      <td>5858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-18 07:00:00</th>\n",
       "      <td>None</td>\n",
       "      <td>293.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>6386.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    holiday    temp  rain_1h  snow_1h  clouds_all  \\\n",
       "2017-06-12 07:00:00    None  290.61      0.0      0.0        90.0   \n",
       "2017-11-01 17:00:00    None  274.15      0.0      0.0        90.0   \n",
       "2018-06-18 07:00:00    None  293.08      0.0      0.0        90.0   \n",
       "\n",
       "                    weather_main      weather_description  traffic_volume  \n",
       "2017-06-12 07:00:00         Mist                     mist          6068.0  \n",
       "2017-11-01 17:00:00      Drizzle  light intensity drizzle          5858.0  \n",
       "2018-06-18 07:00:00         Rain            moderate rain          6386.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_time_series_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note here:\n",
    "\n",
    "* Holidays are not needed given this date is in the US, we can just use the Holidays feature within Forecast: https://docs.aws.amazon.com/forecast/latest/dg/API_SupplementaryFeature.html\n",
    "* Weather description seems to have more variety\n",
    "* Traffic volume will be removed here. \n",
    "* We still need to add back the item_id field.\n",
    "\n",
    "This leaves us with the following schema:\n",
    "\n",
    "* `timestamp` - The Index\n",
    "* `temp` - float\n",
    "* `rain_1h` - float\n",
    "* `snow_1h` - float\n",
    "* `clouds_all` - float\n",
    "* `weather_description` - string\n",
    "* `item_ID` - string\n",
    "\n",
    "The cell below will build that file for us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>269.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>269.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>269.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>269.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>269.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       temp  rain_1h  snow_1h  clouds_all weather_description  \\\n",
       "2017-01-01 00:00:00  269.75      0.0      0.0        75.0       broken clouds   \n",
       "2017-01-01 01:00:00  269.95      0.0      0.0         1.0        sky is clear   \n",
       "2017-01-01 02:00:00  269.75      0.0      0.0         1.0        sky is clear   \n",
       "2017-01-01 03:00:00  269.65      0.0      0.0        40.0    scattered clouds   \n",
       "2017-01-01 04:00:00  269.48      0.0      0.0         1.0        sky is clear   \n",
       "\n",
       "                    item_ID  \n",
       "2017-01-01 00:00:00       1  \n",
       "2017-01-01 01:00:00       1  \n",
       "2017-01-01 02:00:00       1  \n",
       "2017-01-01 03:00:00       1  \n",
       "2017-01-01 04:00:00       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restrict the columns to keep\n",
    "related_time_series_df = related_time_series_df[['temp', 'rain_1h', 'snow_1h', 'clouds_all', 'weather_description']]\n",
    "# Add in item_id\n",
    "related_time_series_df['item_ID'] = \"1\"\n",
    "# Validate the structure\n",
    "related_time_series_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it off as a file:\n",
    "related_time_series_filename = \"related_time_series.csv\"\n",
    "related_time_series_path = data_dir + \"/\" + related_time_series_filename\n",
    "related_time_series_df.to_csv(related_time_series_path, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Related Data to the DatasetGroup\n",
    "\n",
    "Next we are going to create a related-time-series dataset, then add it to our dataset group and finally import our information and validate that it looks good. We will also delete this dataset import after we are done so that the first models do not yet receive any extra info from the related data.\n",
    "\n",
    "You can of course to not delete and get started right away with related data informed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=region)\n",
    "forecast = session.client(service_name='forecast')\n",
    "forecast_query = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Related File\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(related_time_series_filename).upload_file(related_time_series_path)\n",
    "related_s3DataPath = \"s3://\"+bucket_name+\"/\"+related_time_series_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the schema of your dataset here. Make sure the order of columns matches the raw data files.\n",
    "related_schema = {\n",
    "    \"Attributes\": [\n",
    "        {\n",
    "            \"AttributeName\": \"timestamp\",\n",
    "            \"AttributeType\": \"timestamp\",\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"temperature\",\n",
    "            \"AttributeType\": \"float\",\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"rain_1h\",\n",
    "            \"AttributeType\": \"float\",\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"snow_1h\",\n",
    "            \"AttributeType\": \"float\",\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"clouds_all\",\n",
    "            \"AttributeType\": \"float\",\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"weather\",\n",
    "            \"AttributeType\": \"string\",\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"item_id\",\n",
    "            \"AttributeType\": \"string\",\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_DSN = datasetName + \"_related\"\n",
    "response=forecast.create_dataset(\n",
    "                    Domain=\"CUSTOM\",\n",
    "                    DatasetType='RELATED_TIME_SERIES',\n",
    "                    DatasetName=related_DSN,\n",
    "                    DataFrequency=DATASET_FREQUENCY, \n",
    "                    Schema = related_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetArn': 'arn:aws:forecast:ap-southeast-1:024103970757:dataset/forecast_poc_0rj4_ds_related',\n",
       " 'DatasetName': 'forecast_poc_0rj4_ds_related',\n",
       " 'Domain': 'CUSTOM',\n",
       " 'DatasetType': 'RELATED_TIME_SERIES',\n",
       " 'DataFrequency': 'H',\n",
       " 'Schema': {'Attributes': [{'AttributeName': 'timestamp',\n",
       "    'AttributeType': 'timestamp'},\n",
       "   {'AttributeName': 'temperature', 'AttributeType': 'float'},\n",
       "   {'AttributeName': 'rain_1h', 'AttributeType': 'float'},\n",
       "   {'AttributeName': 'snow_1h', 'AttributeType': 'float'},\n",
       "   {'AttributeName': 'clouds_all', 'AttributeType': 'float'},\n",
       "   {'AttributeName': 'weather', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'item_id', 'AttributeType': 'string'}]},\n",
       " 'EncryptionConfig': {},\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2020, 8, 24, 2, 8, 30, 918000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2020, 8, 24, 2, 8, 30, 918000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': 'a783e327-87e2-4392-b480-d5a21cebdcb3',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 24 Aug 2020 02:08:39 GMT',\n",
       "   'x-amzn-requestid': 'a783e327-87e2-4392-b480-d5a21cebdcb3',\n",
       "   'content-length': '734',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_datasetArn = response['DatasetArn']\n",
    "forecast.describe_dataset(DatasetArn=related_datasetArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetImportJobName = 'DSIMPORT_JOB_RELATEDPOC'\n",
    "related_ds_import_job_response=forecast.create_dataset_import_job(DatasetImportJobName=datasetImportJobName,\n",
    "                                                          DatasetArn=related_datasetArn,\n",
    "                                                          DataSource= {\n",
    "                                                              \"S3Config\" : {\n",
    "                                                                 \"Path\":related_s3DataPath,\n",
    "                                                                 \"RoleArn\": role_arn\n",
    "                                                              } \n",
    "                                                          },\n",
    "                                                          TimestampFormat=TIMESTAMP_FORMAT\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:forecast:ap-southeast-1:024103970757:dataset-import-job/forecast_poc_0rj4_ds_related/DSIMPORT_JOB_RELATEDPOC\n"
     ]
    }
   ],
   "source": [
    "rel_ds_import_job_arn=related_ds_import_job_response['DatasetImportJobArn']\n",
    "print(rel_ds_import_job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will poll until the import process has completed, once that has been accomplished we can review the metrics and decide to delete the data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE_PENDING\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "CREATE_IN_PROGRESS\n",
      "ACTIVE\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    dataImportStatus = forecast.describe_dataset_import_job(DatasetImportJobArn=rel_ds_import_job_arn)['Status']\n",
    "    print(dataImportStatus)\n",
    "    if dataImportStatus != 'ACTIVE' and dataImportStatus != 'CREATE_FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Related Time Series Data\n",
    "\n",
    "First let us examine the dataframe that we provided to Forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 18620 entries, 2017-01-01 00:00:00 to 2018-09-30 23:00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   temp                 18620 non-null  float64\n",
      " 1   rain_1h              18620 non-null  float64\n",
      " 2   snow_1h              18620 non-null  float64\n",
      " 3   clouds_all           18620 non-null  float64\n",
      " 4   weather_description  18620 non-null  object \n",
      " 5   item_ID              18620 non-null  object \n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 1018.3+ KB\n"
     ]
    }
   ],
   "source": [
    "related_time_series_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-12 11:00:00</th>\n",
       "      <td>281.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-03 01:00:00</th>\n",
       "      <td>290.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>proximity thunderstorm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-13 13:00:00</th>\n",
       "      <td>297.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       temp  rain_1h  snow_1h  clouds_all  \\\n",
       "2017-04-12 11:00:00  281.35      0.0      0.0         1.0   \n",
       "2017-10-03 01:00:00  290.53      0.0      0.0        90.0   \n",
       "2018-06-13 13:00:00  297.86      0.0      0.0         1.0   \n",
       "\n",
       "                        weather_description item_ID  \n",
       "2017-04-12 11:00:00            sky is clear       1  \n",
       "2017-10-03 01:00:00  proximity thunderstorm       1  \n",
       "2018-06-13 13:00:00            sky is clear       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_time_series_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see 18,609 entries and not one is a NaN value! This is perfect. Now to double check what we imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetImportJobName': 'DSIMPORT_JOB_RELATEDPOC',\n",
       " 'DatasetImportJobArn': 'arn:aws:forecast:ap-southeast-1:024103970757:dataset-import-job/forecast_poc_0rj4_ds_related/DSIMPORT_JOB_RELATEDPOC',\n",
       " 'DatasetArn': 'arn:aws:forecast:ap-southeast-1:024103970757:dataset/forecast_poc_0rj4_ds_related',\n",
       " 'TimestampFormat': 'yyyy-MM-dd hh:mm:ss',\n",
       " 'DataSource': {'S3Config': {'Path': 's3://024103970757-forecastpoc-7a1kn9w9/related_time_series.csv',\n",
       "   'RoleArn': 'arn:aws:iam::024103970757:role/ForecastRolePOC'}},\n",
       " 'FieldStatistics': {'clouds_all': {'Count': 18620,\n",
       "   'CountDistinct': 21,\n",
       "   'CountNull': 0,\n",
       "   'CountNan': 0,\n",
       "   'Min': '0.0',\n",
       "   'Max': '92.0',\n",
       "   'Avg': 48.040655209452204,\n",
       "   'Stddev': 39.55817146688199},\n",
       "  'item_id': {'Count': 18620, 'CountDistinct': 1, 'CountNull': 0},\n",
       "  'rain_1h': {'Count': 18620,\n",
       "   'CountDistinct': 87,\n",
       "   'CountNull': 0,\n",
       "   'CountNan': 0,\n",
       "   'Min': '0.0',\n",
       "   'Max': '10.6',\n",
       "   'Avg': 0.051982277121374876,\n",
       "   'Stddev': 0.4122667356610132},\n",
       "  'snow_1h': {'Count': 18620,\n",
       "   'CountDistinct': 1,\n",
       "   'CountNull': 0,\n",
       "   'CountNan': 0,\n",
       "   'Min': '0.0',\n",
       "   'Max': '0.0',\n",
       "   'Avg': 0.0,\n",
       "   'Stddev': 0.0},\n",
       "  'temperature': {'Count': 18620,\n",
       "   'CountDistinct': 3815,\n",
       "   'CountNull': 0,\n",
       "   'CountNan': 0,\n",
       "   'Min': '246.15',\n",
       "   'Max': '310.07',\n",
       "   'Avg': 282.04625461868955,\n",
       "   'Stddev': 12.550891495009592},\n",
       "  'timestamp': {'Count': 18620,\n",
       "   'CountDistinct': 15312,\n",
       "   'CountNull': 0,\n",
       "   'Min': '2017-01-01T00:00:00Z',\n",
       "   'Max': '2018-09-30T23:00:00Z'},\n",
       "  'weather': {'Count': 18620, 'CountDistinct': 33, 'CountNull': 0}},\n",
       " 'DataSize': 0.0009389687329530716,\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2020, 8, 24, 2, 9, 2, 925000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2020, 8, 24, 2, 11, 8, 976000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': 'b1caf577-3058-4626-b9b2-614657e1927b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 24 Aug 2020 02:16:32 GMT',\n",
       "   'x-amzn-requestid': 'b1caf577-3058-4626-b9b2-614657e1927b',\n",
       "   'content-length': '1966',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.describe_dataset_import_job(DatasetImportJobArn=rel_ds_import_job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! No NaNs or nulls and the entire dataset is ready to go. Once that is done you are ready to move forward building your models with Amazon Forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to update the dataset group to include the related dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '6d5fc93c-06ae-4461-996e-5dbaea7fe62e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 24 Aug 2020 02:17:37 GMT',\n",
       "   'x-amzn-requestid': '6d5fc93c-06ae-4461-996e-5dbaea7fe62e',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.update_dataset_group(DatasetGroupArn=datasetGroupArn, DatasetArns=[target_datasetArn, related_datasetArn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to dis-associate this information from the dataset group so you can build your models without related data simply uncomment the cell below and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast.delete_dataset_import_job(DatasetImportJobArn=rel_ds_import_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
