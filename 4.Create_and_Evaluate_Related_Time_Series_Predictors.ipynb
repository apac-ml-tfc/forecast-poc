{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Evaluating Predictors: Part 2 - Related Time Series\n",
    "\n",
    "This notebook will build off of all the ealrier work and requires that at least the importing of target time series and related time series data be complete. If you have not performed those steps yet, go back, do so, then continue.\n",
    "\n",
    "At this point you now have a target-time-series dataset and a related-time-series dataset loaded into a singular Dataset Group, this is what is required to leverage the models that support related data in Amazon Forecast. If your data supports item level metadata it could be added to the dataset group as well and would benefit only algorithms that support that (e.g. CNN-QR, DeepAR+, but **not** Prophet). \n",
    "\n",
    "To continue the work, start with the imports, determine your region, establish your API connections, and load all previously stored values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "import json\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from IPython.display import Markdown\n",
    "import pprint\n",
    "\n",
    "# Local Dependencies:\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=region)\n",
    "forecast = session.client(service_name='forecast')\n",
    "forecast_query = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training Predictors\n",
    " \n",
    "Given that that our data is hourly and we want to generate a forecast on the hour, Forecast limits us to a horizon of 500 of whatever the slice is. This means we will be able to predict about 20 days into the future.\n",
    "\n",
    "The cells below will define a few variables to be used with all of our models. Then there will be an API call to create each `Predictor` where they are based on Prophet and DeepAR+ respectfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = 240\n",
    "num_backtest_windows = 1\n",
    "backtest_window_offset = 240\n",
    "forecast_frequency = \"H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_algorithm_arn = \"arn:aws:forecast:::algorithm/Prophet\"\n",
    "cnnqr_algorithm_arn = \"arn:aws:forecast:::algorithm/CNN-QR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet Specifics\n",
    "# Note the REL to indicate related time series data\n",
    "prophet_predictor_name = project + \"_prophet_rel_algo_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Prophet:\n",
    "prophet_create_predictor_response = forecast.create_predictor(\n",
    "    PredictorName=prophet_predictor_name,\n",
    "    AlgorithmArn=prophet_algorithm_arn,\n",
    "    ForecastHorizon=forecast_horizon,\n",
    "    PerformAutoML=False,\n",
    "    PerformHPO=False,\n",
    "    EvaluationParameters={\n",
    "        \"NumberOfBacktestWindows\": num_backtest_windows,\n",
    "        \"BackTestWindowOffset\": backtest_window_offset,\n",
    "    },\n",
    "    InputDataConfig={\n",
    "        \"DatasetGroupArn\": datasetGroupArn,\n",
    "        \"SupplementaryFeatures\": [\n",
    "            { \"Name\": \"holiday\", \"Value\": \"US\" }\n",
    "        ],\n",
    "    },\n",
    "    FeaturizationConfig={\n",
    "        \"ForecastFrequency\": forecast_frequency,\n",
    "        \"Featurizations\": [\n",
    "            {\n",
    "                \"AttributeName\": \"target_value\",\n",
    "                \"FeaturizationPipeline\": [\n",
    "                    {\n",
    "                        \"FeaturizationMethodName\": \"filling\",\n",
    "                        \"FeaturizationMethodParameters\": {\n",
    "                            \"frontfill\": \"none\",\n",
    "                            \"middlefill\": \"zero\",\n",
    "                            \"backfill\": \"zero\",\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-QR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-QR Specifics\n",
    "cnnqr_predictor_name = project + \"_cnnqr_rel_algo_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN-QR:\n",
    "cnnqr_create_predictor_response = forecast.create_predictor(\n",
    "    PredictorName=cnnqr_predictor_name,\n",
    "    AlgorithmArn=cnnqr_algorithm_arn,\n",
    "    ForecastHorizon=forecast_horizon,\n",
    "    PerformAutoML=False,\n",
    "    PerformHPO=False,\n",
    "    EvaluationParameters={\n",
    "        \"NumberOfBacktestWindows\": num_backtest_windows,\n",
    "        \"BackTestWindowOffset\": backtest_window_offset,\n",
    "    },\n",
    "    InputDataConfig={\n",
    "        \"DatasetGroupArn\": datasetGroupArn,\n",
    "        \"SupplementaryFeatures\": [\n",
    "            { \"Name\": \"holiday\", \"Value\": \"US\" }\n",
    "        ],\n",
    "    },\n",
    "    FeaturizationConfig={\n",
    "        \"ForecastFrequency\": forecast_frequency,\n",
    "        \"Featurizations\": [\n",
    "            {\n",
    "                \"AttributeName\": \"target_value\",\n",
    "                \"FeaturizationPipeline\": [\n",
    "                    {\n",
    "                        \"FeaturizationMethodName\": \"filling\",\n",
    "                        \"FeaturizationMethodParameters\": {\n",
    "                            \"frontfill\": \"none\",\n",
    "                            \"middlefill\": \"zero\",\n",
    "                            \"backfill\": \"zero\",\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally in our notebooks we would have a while loop that polls for each of these to determine the status of the models in training. For simplicity sake here we are going to rely on you opening a new browser tab and following along in the console until a predictor has been created for each algorithm. \n",
    "\n",
    "Your previous tab from opening this session of Jupyter Lab should still be open, from there navigate to the Amazon Forecast service page, then select your dataset group. Lastly click `Predictors` and you should see the creation in progress. Once they are active you are ready to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the Predictors\n",
    "\n",
    "Once each of the Predictors is in an `Active` state you can get metrics about it to better understand its accuracy and behavior. These are computed based on the hold out periods we defined when building the Predictor. The metrics are meant to guide our decisions when we use a particular Predictor to generate a forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet\n",
    "\n",
    "Here we are going to look to see the metrics from this Predictor like the earlier sessions, we will now add the related data metrics to the table from the previous notebook as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet Metrics\n",
    "prophet_arn = prophet_create_predictor_response['PredictorArn']\n",
    "prophet_rd_metrics = forecast.get_accuracy_metrics(PredictorArn=prophet_arn)\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(prophet_rd_metrics)\n",
    "prophet_rd_RMSEs= util.extract_json_values(prophet_rd_metrics, 'RMSE')\n",
    "markdown_results.append(prophet_rd_RMSEs[0])\n",
    "prophet_rd_loss_values = util.extract_json_values(prophet_rd_metrics, \"LossValue\")\n",
    "markdown_results = markdown_results + prophet_rd_loss_values[::-1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(\"\"\"\n",
    "Here we see an RMSE of {0[12]} which is better than the original \n",
    "RMSE indicating that we may be best served using related data for this algorithm.\n",
    "\n",
    "| Predictor | RMSE               | 10%                 | 50%                 | 90%                |\n",
    "|-----------|--------------------|---------------------|---------------------|--------------------|\n",
    "| ARIMA     | {0[0]}             | {0[1]}              | {0[2]}              | {0[3]}             |\n",
    "| Prophet   | {0[4]}             | {0[5]}              | {0[6]}              | {0[7]}             |\n",
    "| Prophet + Related Data| {0[12]}| {0[13]}             | {0[14]}             | {0[15]}            |\n",
    "| CNN-QR    | {0[8]}             | {0[9]}              | {0[10]}             | {0[11]}            |\n",
    "\n",
    "When digging into the metrics the quantile improvements are mostly marginal. Next let us see how CNN-QR performed.\n",
    "\"\"\".format(markdown_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-QR\n",
    "\n",
    "Same as Prophet, now you should look at the metrics from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-QR Metrics\n",
    "cnnqr_arn = cnnqr_create_predictor_response[\"PredictorArn\"]\n",
    "cnnqr_rd_metrics = forecast.get_accuracy_metrics(PredictorArn=cnnqr_arn)\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(cnnqr_rd_metrics)\n",
    "cnnqr_rd_RMSEs = util.extract_json_values(cnnqr_rd_metrics, \"RMSE\")\n",
    "markdown_results.append(cnnqr_rd_RMSEs[0])\n",
    "cnnqr_rd_loss_values = util.extract_json_values(cnnqr_rd_metrics, \"LossValue\")\n",
    "markdown_results = markdown_results + cnnqr_rd_loss_values[::-1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(\"\"\"\n",
    "Now after training with CNN-QR we can seen an RMSE of {0[16]} which is still not ideal but the full break down is:\n",
    "\n",
    "| Predictor | RMSE               | 10%                 | 50%                 | 90%                |\n",
    "|-----------|--------------------|---------------------|---------------------|--------------------|\n",
    "| ARIMA     | {0[0]}             | {0[1]}              | {0[2]}              | {0[3]}             |\n",
    "| Prophet   | {0[4]}             | {0[5]}              | {0[6]}              | {0[7]}             |\n",
    "| Prophet + Related Data| {0[12]}| {0[13]}             | {0[14]}             | {0[15]}            |\n",
    "| CNN-QR    | {0[8]}             | {0[9]}              | {0[10]}             | {0[11]}            |\n",
    "| CNN-QR + Related Data | {0[16]}| {0[17]}             | {0[18]}             | {0[19]}            |\n",
    "\n",
    "In our test, adding related data actually degraded the performance of CNN-QR. Prophet with related data achieved the\n",
    "lowest combined losses on p10 and p90 quantiles, but for predicting the median and minimising RMSE, CNN-QR without\n",
    "related data was most accurate.\n",
    "\n",
    "Additional work would need to be kicked off from here to determine the specific impact of these figures and how they\n",
    "compare to the existing Forecasting approaches performed by your customer.\n",
    "\"\"\".format(markdown_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
