{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Evaluating Predictors: Part 2 - Related Time Series\n",
    "\n",
    "This notebook will build off of all the ealrier work and requires that at least the importing of target time series and related time series data be complete. If you have not performed those steps yet, go back, do so, then continue.\n",
    "\n",
    "At this point you now have a target-time-series dataset and a related-time-series dataset loaded into a singular Dataset Group, this is what is required to leverage the models that support related data in Amazon Forecast. If your data supports item level metadata it could be added to the dataset group as well and would benefit only DeepAR+. \n",
    "\n",
    "To continue the work, start with the imports, determine your region, establish your API connections, and load all previously stored values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pprint\n",
    "import numpy as np\n",
    "import util\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=region)\n",
    "forecast = session.client(service_name='forecast')\n",
    "forecast_query = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training Predictors\n",
    " \n",
    "Given that that our data is hourly and we want to generate a forecast on the hour, Forecast limits us to a horizon of 500 of whatever the slice is. This means we will be able to predict about 20 days into the future.\n",
    "\n",
    "The cells below will define a few variables to be used with all of our models. Then there will be an API call to create each `Predictor` where they are based on Prophet and DeepAR+ respectfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastHorizon = 480\n",
    "NumberOfBacktestWindows = 1\n",
    "BackTestWindowOffset = 480\n",
    "ForecastFrequency = \"H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_algorithmArn = 'arn:aws:forecast:::algorithm/ARIMA'\n",
    "prophet_algorithmArn = 'arn:aws:forecast:::algorithm/Prophet'\n",
    "deepAR_Plus_algorithmArn = 'arn:aws:forecast:::algorithm/Deep_AR_Plus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet Specifics\n",
    "# Note the REL to indicate related time series data\n",
    "prophet_predictorName= project+'_prophet_rel_algo_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Prophet:\n",
    "prophet_create_predictor_response=forecast.create_predictor(PredictorName=prophet_predictorName, \n",
    "                                                  AlgorithmArn=prophet_algorithmArn,\n",
    "                                                  ForecastHorizon=forecastHorizon,\n",
    "                                                  PerformAutoML= False,\n",
    "                                                  PerformHPO=False,\n",
    "                                                  EvaluationParameters= {\"NumberOfBacktestWindows\": NumberOfBacktestWindows, \n",
    "                                                                         \"BackTestWindowOffset\": BackTestWindowOffset}, \n",
    "                                                  InputDataConfig= {\"DatasetGroupArn\": datasetGroupArn, \"SupplementaryFeatures\": [ \n",
    "                                                                     { \n",
    "                                                                        \"Name\": \"holiday\",\n",
    "                                                                        \"Value\": \"US\"\n",
    "                                                                     }\n",
    "                                                                  ]},\n",
    "                                                  FeaturizationConfig= {\"ForecastFrequency\": ForecastFrequency, \n",
    "                                                                        \"Featurizations\": \n",
    "                                                                        [\n",
    "                                                                          {\"AttributeName\": \"target_value\", \n",
    "                                                                           \"FeaturizationPipeline\": \n",
    "                                                                            [\n",
    "                                                                              {\"FeaturizationMethodName\": \"filling\", \n",
    "                                                                               \"FeaturizationMethodParameters\": \n",
    "                                                                                {\"frontfill\": \"none\", \n",
    "                                                                                 \"middlefill\": \"zero\", \n",
    "                                                                                 \"backfill\": \"zero\"}\n",
    "                                                                              }\n",
    "                                                                            ]\n",
    "                                                                          }\n",
    "                                                                        ]\n",
    "                                                                       }\n",
    "                                                 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepAR+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR+ Specifics\n",
    "prophet_predictorName= project+'_deeparp_rel_algo_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DeepAR+:\n",
    "deeparp_create_predictor_response=forecast.create_predictor(PredictorName=prophet_predictorName, \n",
    "                                                  AlgorithmArn=deepAR_Plus_algorithmArn,\n",
    "                                                  ForecastHorizon=forecastHorizon,\n",
    "                                                  PerformAutoML= False,\n",
    "                                                  PerformHPO=False,\n",
    "                                                  EvaluationParameters= {\"NumberOfBacktestWindows\": NumberOfBacktestWindows, \n",
    "                                                                         \"BackTestWindowOffset\": BackTestWindowOffset}, \n",
    "                                                  InputDataConfig= {\"DatasetGroupArn\": datasetGroupArn, \"SupplementaryFeatures\": [ \n",
    "                                                                     { \n",
    "                                                                        \"Name\": \"holiday\",\n",
    "                                                                        \"Value\": \"US\"\n",
    "                                                                     }\n",
    "                                                                  ]},\n",
    "                                                  FeaturizationConfig= {\"ForecastFrequency\": ForecastFrequency, \n",
    "                                                                        \"Featurizations\": \n",
    "                                                                        [\n",
    "                                                                          {\"AttributeName\": \"target_value\", \n",
    "                                                                           \"FeaturizationPipeline\": \n",
    "                                                                            [\n",
    "                                                                              {\"FeaturizationMethodName\": \"filling\", \n",
    "                                                                               \"FeaturizationMethodParameters\": \n",
    "                                                                                {\"frontfill\": \"none\", \n",
    "                                                                                 \"middlefill\": \"zero\", \n",
    "                                                                                 \"backfill\": \"zero\"}\n",
    "                                                                              }\n",
    "                                                                            ]\n",
    "                                                                          }\n",
    "                                                                        ]\n",
    "                                                                       }\n",
    "                                                 )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally in our notebooks we would have a while loop that polls for each of these to determine the status of the models in training. For simplicity sake here we are going to rely on you opening a new browser tab and following along in the console until a predictor has been created for each algorithm. \n",
    "\n",
    "Your previous tab from opening this session of Jupyter Lab should still be open, from there navigate to the Amazon Forecast service page, then select your dataset group. Lastly click `Predictors` and you should see the creation in progress. Once they are active you are ready to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the Predictors\n",
    "\n",
    "Once each of the Predictors is in an `Active` state you can get metrics about it to better understand its accuracy and behavior. These are computed based on the hold out periods we defined when building the Predictor. The metrics are meant to guide our decisions when we use a particular Predictor to generate a forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet\n",
    "\n",
    "Here we are going to look to see the metrics from this Predictor like the earlier sessions, we will now add the related data metrics to the table from the previous notebook as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet Metrics\n",
    "prophet_arn = prophet_create_predictor_response['PredictorArn']\n",
    "prophet_rd_metrics = forecast.get_accuracy_metrics(PredictorArn=prophet_arn)\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(prophet_rd_metrics)\n",
    "prophet_rd_RMSEs= util.extract_json_values(prophet_rd_metrics, 'RMSE')\n",
    "prophet_rd_RMSE = prophet_rd_RMSEs[0]\n",
    "prophet_rd_lossValues = util.extract_json_values(prophet_rd_metrics, 'LossValue')\n",
    "prophet_rd_wQuantileLoss_90, prophet_rd_wQuantileLoss_50, prophet_rd_wQuantileLoss_10 = prophet_rd_lossValues[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(\"\"\"\n",
    "Here we see an RMSE of {prophet_rd_RMSE} which is better than the original \n",
    "RMSE indicating that we may not be best served using related data for this algorithm.\n",
    "\n",
    "| Predictor | RMSE               | 10%                 | 50%                 | 90%                |\n",
    "|-----------|--------------------|---------------------|---------------------|--------------------|\n",
    "| ARIMA     | {arima_RMSE}         | {arima_wQuantileLoss_10}       | {arima_wQuantileLoss_50}    | {arima_wQuantileLoss_90}      |\n",
    "| Prophet   | {prophet_RMSE}       | {prophet_wQuantileLoss_10}       | {prophet_wQuantileLoss_50}    | {prophet_wQuantileLoss_90}      |\n",
    "| Prophet + Related Data\t   | {prophet_rd_RMSE}       | {prophet_rd_wQuantileLoss_10}       | {prophet_rd_wQuantileLoss_50}    | {prophet_rd_wQuantileLoss_90}      |\n",
    "| DeepAR+   | {deeparp_RMSE}       | {deeparp_wQuantileLoss_10}     | {deeparp_wQuantileLoss_50}  | {deeparp_wQuantileLoss_90} |\n",
    "\n",
    "When digging into the metrics we did not see a single improvement to Prophet, next let us see how DeepAR+ performed.\n",
    "\"\"\".format(arima_RMSE=arima_RMSE, arima_wQuantileLoss_10=arima_wQuantileLoss_10, \n",
    "           arima_wQuantileLoss_50=arima_wQuantileLoss_50, arima_wQuantileLoss_90=arima_wQuantileLoss_90,\n",
    "           prophet_RMSE=prophet_RMSE, prophet_wQuantileLoss_10=prophet_wQuantileLoss_10, \n",
    "           prophet_wQuantileLoss_50=prophet_wQuantileLoss_50, prophet_wQuantileLoss_90=prophet_wQuantileLoss_90,\n",
    "           prophet_rd_RMSE=prophet_rd_RMSE, prophet_rd_wQuantileLoss_10=prophet_rd_wQuantileLoss_10, \n",
    "           prophet_rd_wQuantileLoss_50=prophet_rd_wQuantileLoss_50, prophet_rd_wQuantileLoss_90=prophet_rd_wQuantileLoss_90,\n",
    "           deeparp_RMSE=deeparp_RMSE, deeparp_wQuantileLoss_10=deeparp_wQuantileLoss_10, \n",
    "           deeparp_wQuantileLoss_50=deeparp_wQuantileLoss_50, deeparp_wQuantileLoss_90=deeparp_wQuantileLoss_90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepAR+\n",
    "\n",
    "Same as Prophet, now you should look at the metrics from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR+ Metrics\n",
    "deeparp_arn = deeparp_create_predictor_response['PredictorArn']\n",
    "deeparp_rd_metrics = forecast.get_accuracy_metrics(PredictorArn=deeparp_arn)\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(deeparp_rd_metrics)\n",
    "deeparp_rd_RMSEs= util.extract_json_values(deeparp_rd_metrics, 'RMSE')\n",
    "deeparp_rd_RMSE = deeparp_rd_RMSEs[0]\n",
    "deeparp_rd_lossValues = util.extract_json_values(deeparp_rd_metrics, 'LossValue')\n",
    "deeparp_rd_wQuantileLoss_90, deeparp_rd_wQuantileLoss_50, deeparp_rd_wQuantileLoss_10 = deeparp_rd_lossValues[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(\"\"\"\n",
    "Now after training with DeepAR+ we can seen an RMSE of {prophet_rd_RMSE} which is still not ideal but the full break down is:\n",
    "\n",
    "| Predictor | RMSE               | 10%                 | 50%                 | 90%                |\n",
    "|-----------|--------------------|---------------------|---------------------|--------------------|\n",
    "| ARIMA     | {arima_RMSE}         | {arima_wQuantileLoss_10}       | {arima_wQuantileLoss_50}    | {arima_wQuantileLoss_90}      |\n",
    "| Prophet   | {prophet_RMSE}       | {prophet_wQuantileLoss_10}       | {prophet_wQuantileLoss_50}    | {prophet_wQuantileLoss_90}      |\n",
    "| Prophet + Related Data | {prophet_rd_RMSE}       | {prophet_rd_wQuantileLoss_10}       | {prophet_rd_wQuantileLoss_50}    | {prophet_rd_wQuantileLoss_90}      |\n",
    "| DeepAR+   | {deeparp_RMSE}       | {deeparp_wQuantileLoss_10}     | {deeparp_wQuantileLoss_50}  | {deeparp_wQuantileLoss_90} |\n",
    "| DeepAR+ & Related Data | {deeparp_rd_RMSE}       | {deeparp_rd_wQuantileLoss_10}     | {deeparp_rd_wQuantileLoss_50}  | {deeparp_rd_wQuantileLoss_90} |\n",
    "\n",
    "From this table we can see that DeepAR+ with the related data is the leader for the 10% and 50% quantiles. If you are predicting in this range then it is a clear leader for usage. However if 90% is the target then DeepAR+ is the leader for now.\n",
    "\n",
    "Additional work would need to be kicked off from here to determine the specific impact of these figures and how they compare to the existing Forecasting approaches performed by your customer.\n",
    "\"\"\".format(arima_RMSE=arima_RMSE, arima_wQuantileLoss_10=arima_wQuantileLoss_10, \n",
    "           arima_wQuantileLoss_50=arima_wQuantileLoss_50, arima_wQuantileLoss_90=arima_wQuantileLoss_90,\n",
    "           prophet_RMSE=prophet_RMSE, prophet_wQuantileLoss_10=prophet_wQuantileLoss_10, \n",
    "           prophet_wQuantileLoss_50=prophet_wQuantileLoss_50, prophet_wQuantileLoss_90=prophet_wQuantileLoss_90,\n",
    "           prophet_rd_RMSE=prophet_rd_RMSE, prophet_rd_wQuantileLoss_10=prophet_rd_wQuantileLoss_10, \n",
    "           prophet_rd_wQuantileLoss_50=prophet_rd_wQuantileLoss_50, prophet_rd_wQuantileLoss_90=prophet_rd_wQuantileLoss_90,\n",
    "           deeparp_RMSE=deeparp_RMSE, deeparp_wQuantileLoss_10=deeparp_wQuantileLoss_10, \n",
    "           deeparp_wQuantileLoss_50=deeparp_wQuantileLoss_50, deeparp_wQuantileLoss_90=deeparp_wQuantileLoss_90,\n",
    "           deeparp_rd_RMSE=deeparp_rd_RMSE, deeparp_rd_wQuantileLoss_10=deeparp_wQuantileLoss_10, \n",
    "           deeparp_rd_wQuantileLoss_50=deeparp_rd_wQuantileLoss_50, deeparp_rd_wQuantileLoss_90=deeparp_rd_wQuantileLoss_90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
